import cv2
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import json, urllib
import cv2  # OpenCV: ë™ì˜ìƒ/ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import torch  # PyTorch: ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
import torchvision.models as models  # ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ ì œê³µ
import torchvision.transforms as transforms  # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë„êµ¬
from PIL import Image  # ì´ë¯¸ì§€ íŒŒì¼ì„ ë‹¤ë£¨ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import json, urllib  # json: ë°ì´í„° ì²˜ë¦¬, urllib: ì¸í„°ë„·ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
import asyncio


from service.memory_manager import MemoryManager

class CVManager:
	def __init__(self, db: MemoryManager, send_callback):
		self.db = db
		self.send_callback = send_callback
		# 1. ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
		self.model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
		self.model.eval()
		self.slow_until = 0

		# 2. ImageNet í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ë¡œë“œ
		url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
		self.imagenet_classes = urllib.request.urlopen(url).read().decode("utf-8").splitlines()

		# 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬: ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
		# - í¬ê¸° ì¡°ì •, ê°€ìš´ë° ìë¥´ê¸°, í…ì„œ ë³€í™˜, ì •ê·œí™”
		self.transform = transforms.Compose([
			transforms.Resize(256),  # ì§§ì€ ë³€ ê¸°ì¤€ 256í”½ì…€ë¡œ í¬ê¸° ì¡°ì •
			transforms.CenterCrop(224),  # ì¤‘ì•™ 224x224ë¡œ ìë¥´ê¸°
			transforms.ToTensor(),  # ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
			transforms.Normalize(
				mean=[0.485, 0.456, 0.406],  # ê° ì±„ë„ë³„ í‰ê· ê°’
				std=[0.229, 0.224, 0.225]    # ê° ì±„ë„ë³„ í‘œì¤€í¸ì°¨
			)
		])

	def play_video(self, video_file, loop):
		# ë™ì˜ìƒ íŒŒì¼ì—ì„œ í”„ë ˆì„ì„ í•˜ë‚˜ì”© ì½ì–´ì„œ ë¶„ë¥˜
		self.cap = cv2.VideoCapture(video_file)  # ë™ì˜ìƒ íŒŒì¼ ì—´ê¸°
		asyncio.run_coroutine_threadsafe(self.send_callback("video-control", "play"), loop)

		frame_id = 0  # í”„ë ˆì„ ë²ˆí˜¸ ì´ˆê¸°í™”
		while self.cap.isOpened():  # ë™ì˜ìƒì´ ì—´ë ¤ìˆëŠ” ë™ì•ˆ ë°˜ë³µ
			ret, frame = self.cap.read()  # í•œ í”„ë ˆì„ ì½ê¸°
			if not ret:  # ë” ì´ìƒ ì½ì„ í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
				break
			
			# OpenCV í”„ë ˆì„(BGR)ì„ PIL ì´ë¯¸ì§€(RGB)ë¡œ ë³€í™˜
			img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).convert("RGB")
			img_t = self.transform(img).unsqueeze(0)  # ì „ì²˜ë¦¬ ë° ë°°ì¹˜ ì°¨ì› ì¶”ê°€

			with torch.no_grad():  # ì¶”ë¡  ì‹œì—ëŠ” ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™”
				outputs = self.model(img_t)  # ëª¨ë¸ì— ì…ë ¥
				probs = torch.nn.functional.softmax(outputs[0], dim=0)  # í™•ë¥ ë¡œ ë³€í™˜

			# ê°€ì¥ í™•ë¥ ì´ ë†’ì€(top3) í´ë˜ìŠ¤ì™€ ì ìˆ˜ ì¶”ì¶œ
			top3 = torch.topk(probs, 3)
			top3_list = []
			for indice, value in zip(top3.indices, top3.values):
				label = self.imagenet_classes[indice]  # í´ë˜ìŠ¤ ì´ë¦„
				score = value.item()  # í™•ë¥  ì ìˆ˜
				# í”„ë ˆì„ ë²ˆí˜¸, ì˜ˆì¸¡ ê²°ê³¼, ì ìˆ˜ ì¶œë ¥
				top3_list.append({"label": label, "prob": score})

			frame_id += 1  # í”„ë ˆì„ ë²ˆí˜¸ ì¦ê°€

			if self.db.validate_object(top3_list):
				self.slow_until = 10
				# ğŸ”¥ ì—¬ê¸°ì„œ ë©”ì‹œì§€ ë³´ë‚´ê¸°
				if self.send_callback:
					# ë™ê¸° í•¨ìˆ˜ë¼ ì§ì ‘ await ëª» í•¨ â†’ run_coroutine_threadsafe ì‚¬ìš©
					asyncio.run_coroutine_threadsafe(
						self.send_callback("video-control", "0.1"), loop
					)
			if self.slow_until > 0:
				# í”„ë ˆì„ ìƒë‹¨ì— í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
				cv2.putText(frame, self.db.current_object, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
				self.slow_until -= 1
				if cv2.waitKey(500) & 0xFF == 27:
					break
			else:
				asyncio.run_coroutine_threadsafe(
					self.send_callback("video-control", "1"), loop
				)
				if cv2.waitKey(10) & 0xFF == 27:
					break
	
		self.cap.release()

